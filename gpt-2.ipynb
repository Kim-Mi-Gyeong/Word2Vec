{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. 데이터 로드","metadata":{}},{"cell_type":"code","source":"# 데이터 로드를 위함\nfrom datasets import load_dataset\n\n# 기본 파이썬 패키지\nimport pandas as pd\nimport numpy as np\nimport datetime\nfrom tqdm import tqdm\n\n# GPT 사용을 위함\nimport torch\nfrom transformers import BertTokenizer\nfrom transformers import BertForSequenceClassification, AdamW, BertConfig\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n# for padding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# 전처리 및 평가 지표\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:08:15.929574Z","iopub.execute_input":"2025-01-23T03:08:15.929860Z","iopub.status.idle":"2025-01-23T03:08:36.839540Z","shell.execute_reply.started":"2025-01-23T03:08:15.929832Z","shell.execute_reply":"2025-01-23T03:08:36.838602Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:09:48.278888Z","iopub.execute_input":"2025-01-23T03:09:48.279285Z","iopub.status.idle":"2025-01-23T03:09:48.608953Z","shell.execute_reply.started":"2025-01-23T03:09:48.279244Z","shell.execute_reply":"2025-01-23T03:09:48.608013Z"}},"outputs":[{"name":"stdout","text":"--2025-01-23 03:09:48--  https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1319001 (1.3M) [text/plain]\nSaving to: ‘finance_data.csv’\n\nfinance_data.csv    100%[===================>]   1.26M  --.-KB/s    in 0.06s   \n\n2025-01-23 03:09:48 (21.8 MB/s) - ‘finance_data.csv’ saved [1319001/1319001]\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv('finance_data.csv')\nprint('샘플의 개수 :', len(df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:10:08.694225Z","iopub.execute_input":"2025-01-23T03:10:08.694556Z","iopub.status.idle":"2025-01-23T03:10:08.736166Z","shell.execute_reply.started":"2025-01-23T03:10:08.694528Z","shell.execute_reply":"2025-01-23T03:10:08.735309Z"}},"outputs":[{"name":"stdout","text":"샘플의 개수 : 4846\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:10:14.854341Z","iopub.execute_input":"2025-01-23T03:10:14.854799Z","iopub.status.idle":"2025-01-23T03:10:14.885350Z","shell.execute_reply.started":"2025-01-23T03:10:14.854756Z","shell.execute_reply":"2025-01-23T03:10:14.884468Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        labels                                           sentence  \\\n0      neutral  According to Gran, the company has no plans to...   \n1      neutral  Technopolis plans to develop in stages an area...   \n2     negative  The international electronic industry company ...   \n3     positive  With the new production plant the company woul...   \n4     positive  According to the company's updated strategy fo...   \n...        ...                                                ...   \n4841  negative  LONDON MarketWatch -- Share prices ended lower...   \n4842   neutral  Rinkuskiai's beer sales fell by 6.5 per cent t...   \n4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...   \n4844  negative  Net sales of the Paper segment decreased to EU...   \n4845  negative  Sales in Finland decreased by 10.5 % in Januar...   \n\n                                           kor_sentence  \n0     Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n1     테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n2     국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n3     새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n4     2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  \n...                                                 ...  \n4841  런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...  \n4842  린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...  \n4843  영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...  \n4844  페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...  \n4845   핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.  \n\n[4846 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>sentence</th>\n      <th>kor_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>According to Gran, the company has no plans to...</td>\n      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neutral</td>\n      <td>Technopolis plans to develop in stages an area...</td>\n      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>negative</td>\n      <td>The international electronic industry company ...</td>\n      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>positive</td>\n      <td>With the new production plant the company woul...</td>\n      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>positive</td>\n      <td>According to the company's updated strategy fo...</td>\n      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4841</th>\n      <td>negative</td>\n      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n      <td>런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...</td>\n    </tr>\n    <tr>\n      <th>4842</th>\n      <td>neutral</td>\n      <td>Rinkuskiai's beer sales fell by 6.5 per cent t...</td>\n      <td>린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...</td>\n    </tr>\n    <tr>\n      <th>4843</th>\n      <td>negative</td>\n      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n      <td>영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...</td>\n    </tr>\n    <tr>\n      <th>4844</th>\n      <td>negative</td>\n      <td>Net sales of the Paper segment decreased to EU...</td>\n      <td>페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...</td>\n    </tr>\n    <tr>\n      <th>4845</th>\n      <td>negative</td>\n      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n      <td>핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.</td>\n    </tr>\n  </tbody>\n</table>\n<p>4846 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:10:38.645891Z","iopub.execute_input":"2025-01-23T03:10:38.646208Z","iopub.status.idle":"2025-01-23T03:10:38.654877Z","shell.execute_reply.started":"2025-01-23T03:10:38.646187Z","shell.execute_reply":"2025-01-23T03:10:38.653788Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     labels                                           sentence  \\\n0   neutral  According to Gran, the company has no plans to...   \n1   neutral  Technopolis plans to develop in stages an area...   \n2  negative  The international electronic industry company ...   \n3  positive  With the new production plant the company woul...   \n4  positive  According to the company's updated strategy fo...   \n\n                                        kor_sentence  \n0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>sentence</th>\n      <th>kor_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>According to Gran, the company has no plans to...</td>\n      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neutral</td>\n      <td>Technopolis plans to develop in stages an area...</td>\n      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>negative</td>\n      <td>The international electronic industry company ...</td>\n      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>positive</td>\n      <td>With the new production plant the company woul...</td>\n      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>positive</td>\n      <td>According to the company's updated strategy fo...</td>\n      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df['labels'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:12:23.387598Z","iopub.execute_input":"2025-01-23T03:12:23.387969Z","iopub.status.idle":"2025-01-23T03:12:23.400642Z","shell.execute_reply.started":"2025-01-23T03:12:23.387944Z","shell.execute_reply":"2025-01-23T03:12:23.399929Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"labels\nneutral     2879\npositive    1363\nnegative     604\nName: count, dtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:12:49.307088Z","iopub.execute_input":"2025-01-23T03:12:49.307369Z","iopub.status.idle":"2025-01-23T03:12:49.321240Z","shell.execute_reply.started":"2025-01-23T03:12:49.307349Z","shell.execute_reply":"2025-01-23T03:12:49.320210Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-910beaa298a3>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   labels                                           sentence  \\\n0       0  According to Gran, the company has no plans to...   \n1       0  Technopolis plans to develop in stages an area...   \n2       2  The international electronic industry company ...   \n3       1  With the new production plant the company woul...   \n4       1  According to the company's updated strategy fo...   \n\n                                        kor_sentence  \n0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>sentence</th>\n      <th>kor_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>According to Gran, the company has no plans to...</td>\n      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Technopolis plans to develop in stages an area...</td>\n      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>The international electronic industry company ...</td>\n      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>With the new production plant the company woul...</td>\n      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>According to the company's updated strategy fo...</td>\n      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df.to_csv('finance_data.csv', index=False, encoding='utf-8-sig')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:13:19.217453Z","iopub.execute_input":"2025-01-23T03:13:19.217788Z","iopub.status.idle":"2025-01-23T03:13:19.255238Z","shell.execute_reply.started":"2025-01-23T03:13:19.217756Z","shell.execute_reply":"2025-01-23T03:13:19.254544Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"all_data = load_dataset(\n        \"csv\",\n        data_files={\n            \"train\": \"finance_data.csv\",\n        },\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:13:41.792956Z","iopub.execute_input":"2025-01-23T03:13:41.793236Z","iopub.status.idle":"2025-01-23T03:13:42.041804Z","shell.execute_reply.started":"2025-01-23T03:13:41.793217Z","shell.execute_reply":"2025-01-23T03:13:42.040921Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b1eb357732945ecba279fb6eb014052"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"cs = all_data['train'].train_test_split(0.2, seed=777)\ntrain_cs = cs[\"train\"]\ntest_cs = cs[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:15:39.031510Z","iopub.execute_input":"2025-01-23T03:15:39.031911Z","iopub.status.idle":"2025-01-23T03:15:39.045288Z","shell.execute_reply.started":"2025-01-23T03:15:39.031880Z","shell.execute_reply":"2025-01-23T03:15:39.044359Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"all_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:15:48.926809Z","iopub.execute_input":"2025-01-23T03:15:48.927150Z","iopub.status.idle":"2025-01-23T03:15:48.932363Z","shell.execute_reply.started":"2025-01-23T03:15:48.927123Z","shell.execute_reply":"2025-01-23T03:15:48.931528Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['labels', 'sentence', 'kor_sentence'],\n        num_rows: 4846\n    })\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"cs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:15:59.191636Z","iopub.execute_input":"2025-01-23T03:15:59.192005Z","iopub.status.idle":"2025-01-23T03:15:59.197386Z","shell.execute_reply.started":"2025-01-23T03:15:59.191974Z","shell.execute_reply":"2025-01-23T03:15:59.196553Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['labels', 'sentence', 'kor_sentence'],\n        num_rows: 3876\n    })\n    test: Dataset({\n        features: ['labels', 'sentence', 'kor_sentence'],\n        num_rows: 970\n    })\n})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"train_cs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:16:29.615706Z","iopub.execute_input":"2025-01-23T03:16:29.616098Z","iopub.status.idle":"2025-01-23T03:16:29.620796Z","shell.execute_reply.started":"2025-01-23T03:16:29.616059Z","shell.execute_reply":"2025-01-23T03:16:29.620060Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'sentence', 'kor_sentence'],\n    num_rows: 3876\n})"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"test_cs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:16:43.782149Z","iopub.execute_input":"2025-01-23T03:16:43.782421Z","iopub.status.idle":"2025-01-23T03:16:43.787817Z","shell.execute_reply.started":"2025-01-23T03:16:43.782400Z","shell.execute_reply":"2025-01-23T03:16:43.786929Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'sentence', 'kor_sentence'],\n    num_rows: 970\n})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# 훈련 데이터를 다시 8:2로 분리 후 훈련 데이터와 검증 데이터로 저장\ncs = train_cs.train_test_split(0.2, seed=777)\ntrain_cs = cs[\"train\"]\nvalid_cs = cs[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:17:27.828512Z","iopub.execute_input":"2025-01-23T03:17:27.828847Z","iopub.status.idle":"2025-01-23T03:17:27.843752Z","shell.execute_reply.started":"2025-01-23T03:17:27.828823Z","shell.execute_reply":"2025-01-23T03:17:27.842826Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"cs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:17:32.847691Z","iopub.execute_input":"2025-01-23T03:17:32.848070Z","iopub.status.idle":"2025-01-23T03:17:32.853379Z","shell.execute_reply.started":"2025-01-23T03:17:32.848041Z","shell.execute_reply":"2025-01-23T03:17:32.852400Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['labels', 'sentence', 'kor_sentence'],\n        num_rows: 3100\n    })\n    test: Dataset({\n        features: ['labels', 'sentence', 'kor_sentence'],\n        num_rows: 776\n    })\n})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"print('두번째 샘플 출력 :', train_cs['kor_sentence'][1])\nprint('두번째 샘플의 레이블 출력 :', train_cs['labels'][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:17:53.220488Z","iopub.execute_input":"2025-01-23T03:17:53.220841Z","iopub.status.idle":"2025-01-23T03:17:53.260448Z","shell.execute_reply.started":"2025-01-23T03:17:53.220811Z","shell.execute_reply":"2025-01-23T03:17:53.259449Z"}},"outputs":[{"name":"stdout","text":"두번째 샘플 출력 : 알마 미디어 코퍼레이션 사업 ID 1944757-4의 주식 자본금은 44,767,513.80유로이며 74,612,523주로 나뉜다.\n두번째 샘플의 레이블 출력 : 0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# 2. 데이터 전처리","metadata":{}},{"cell_type":"code","source":"# 훈련 데이터, 검증 데이터, 테스트 데이터\ntrain_sentences = list(train_cs['kor_sentence'])\nvalidation_sentences = list(valid_cs['kor_sentence'])\ntest_sentences = list(test_cs['kor_sentence'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:18:16.355972Z","iopub.execute_input":"2025-01-23T03:18:16.356295Z","iopub.status.idle":"2025-01-23T03:18:16.385879Z","shell.execute_reply.started":"2025-01-23T03:18:16.356268Z","shell.execute_reply":"2025-01-23T03:18:16.384997Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train_labels = train_cs['labels']\nvalidation_labels = valid_cs['labels']\ntest_labels = test_cs['labels']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:18:37.212280Z","iopub.execute_input":"2025-01-23T03:18:37.212603Z","iopub.status.idle":"2025-01-23T03:18:37.237039Z","shell.execute_reply.started":"2025-01-23T03:18:37.212575Z","shell.execute_reply":"2025-01-23T03:18:37.236254Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"test_sentences[:5]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:19:11.210625Z","iopub.execute_input":"2025-01-23T03:19:11.210978Z","iopub.status.idle":"2025-01-23T03:19:11.216707Z","shell.execute_reply.started":"2025-01-23T03:19:11.210954Z","shell.execute_reply":"2025-01-23T03:19:11.215904Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"['오전 10.58시 아우토쿰푸는 2.74pct 하락한 24.87유로, OMX 헬싱키 25지수는 0.55pct 상승한 2,825.14, OMX 헬싱키는 0.64pct 하락한 9,386.89유로에 거래됐다.',\n '10월부터 12월까지의 판매량은 302 mln 유로로 전년 동기 대비 25.3 pct 증가했다.',\n '매디슨, 위스콘신, 2월 6일 - PRNewswire - - 피스카스는 미국 특허청이 상징적인 가위 손잡이에 오렌지색 상표 등록을 허가했다고 발표한다.',\n \"M-real로 평가된 분석가들 중 총 6명은 ''매수' - ''누적''을 주었고, 3명은 ''보유'', 1명만이 ''매도''를 주었다.\",\n '주요 양조업체들은 지난해 국내 맥주 판매량을 2004년 2억4592만 리터에서 2억5688만 리터로 4.5% 늘렸다.']"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"test_sentences[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:21:33.199650Z","iopub.execute_input":"2025-01-23T03:21:33.200018Z","iopub.status.idle":"2025-01-23T03:21:33.206003Z","shell.execute_reply.started":"2025-01-23T03:21:33.199990Z","shell.execute_reply":"2025-01-23T03:21:33.205139Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"['오전 10.58시 아우토쿰푸는 2.74pct 하락한 24.87유로, OMX 헬싱키 25지수는 0.55pct 상승한 2,825.14, OMX 헬싱키는 0.64pct 하락한 9,386.89유로에 거래됐다.',\n '10월부터 12월까지의 판매량은 302 mln 유로로 전년 동기 대비 25.3 pct 증가했다.',\n '매디슨, 위스콘신, 2월 6일 - PRNewswire - - 피스카스는 미국 특허청이 상징적인 가위 손잡이에 오렌지색 상표 등록을 허가했다고 발표한다.',\n \"M-real로 평가된 분석가들 중 총 6명은 ''매수' - ''누적''을 주었고, 3명은 ''보유'', 1명만이 ''매도''를 주었다.\",\n '주요 양조업체들은 지난해 국내 맥주 판매량을 2004년 2억4592만 리터에서 2억5688만 리터로 4.5% 늘렸다.']"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# 3. GPT 토크나이저를 이용한 전처리","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:21:00.336183Z","iopub.execute_input":"2025-01-23T03:21:00.336493Z","iopub.status.idle":"2025-01-23T03:21:00.372324Z","shell.execute_reply.started":"2025-01-23T03:21:00.336472Z","shell.execute_reply":"2025-01-23T03:21:00.371213Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# 한국어 GPT 중 하나인 'skt/kogpt2-base-v2'를 사용.\ntokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:21:04.713162Z","iopub.execute_input":"2025-01-23T03:21:04.713486Z","iopub.status.idle":"2025-01-23T03:21:05.650951Z","shell.execute_reply.started":"2025-01-23T03:21:04.713458Z","shell.execute_reply":"2025-01-23T03:21:05.650241Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d205fb65e3cc4d50bb94303b4ea5bc4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f20799de43c04263a24980a5ebae8388"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# 최대 길이는 128\nMAX_LEN = 128\n\ndef data_to_tensor (sentences, labels, max_len):\n  # 정수 인코딩 과정. 각 텍스트를 토큰화한 후에 Vocabulary에 맵핑되는 정수 시퀀스로 변환한다.\n  # ex) ['안녕하세요'] ==> ['안', '녕', '하세요'] ==> [231, 52, 45]\n  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n\n  # pad_sequences는 패딩을 위한 모듈. 주어진 최대 길이를 위해서 뒤에서 패딩 토큰의 번호로 채워준다.\n  # ex) [231, 52, 45] ==> [231, 52, 45, 패딩 토큰, 패딩 토큰, 패딩 토큰]\n  pad_token = tokenizer.encode('<pad>')[0]\n  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, value=pad_token, dtype=\"long\", truncating=\"post\", padding=\"post\") \n\n  attention_masks = []\n\n  for seq in input_ids:\n      seq_mask = [float(i != pad_token) for i in seq]\n      attention_masks.append(seq_mask)\n\n  tensor_inputs = torch.tensor(input_ids)\n  tensor_labels = torch.tensor(labels)\n  tensor_masks = torch.tensor(attention_masks)\n\n  return tensor_inputs, tensor_labels, tensor_masks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:26:07.634462Z","iopub.execute_input":"2025-01-23T03:26:07.634795Z","iopub.status.idle":"2025-01-23T03:26:07.640330Z","shell.execute_reply.started":"2025-01-23T03:26:07.634758Z","shell.execute_reply":"2025-01-23T03:26:07.639436Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# 학습 데이터, 검증 데이터, 테스트 데이터에 대해서\n# 정수 인코딩 결과, 레이블, 어텐션 마스크를 각각 inputs, labels, masks에 저장.\ntrain_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels, max_len)\nvalidation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels, max_len)\ntest_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels, max_len)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:26:10.948110Z","iopub.execute_input":"2025-01-23T03:26:10.948423Z","iopub.status.idle":"2025-01-23T03:26:11.817295Z","shell.execute_reply.started":"2025-01-23T03:26:10.948396Z","shell.execute_reply":"2025-01-23T03:26:11.816559Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"data_to_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:35:13.834894Z","iopub.execute_input":"2025-01-23T03:35:13.835225Z","iopub.status.idle":"2025-01-23T03:35:13.840416Z","shell.execute_reply.started":"2025-01-23T03:35:13.835203Z","shell.execute_reply":"2025-01-23T03:35:13.839640Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<function __main__.data_to_tensor(sentences, labels, max_len)>"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"# 4. 데이터의 배치화","metadata":{}},{"cell_type":"code","source":"batch_size = 32\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:35:36.671657Z","iopub.execute_input":"2025-01-23T03:35:36.672001Z","iopub.status.idle":"2025-01-23T03:35:36.678503Z","shell.execute_reply.started":"2025-01-23T03:35:36.671974Z","shell.execute_reply":"2025-01-23T03:35:36.677769Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:43:40.877430Z","iopub.execute_input":"2025-01-23T03:43:40.877827Z","iopub.status.idle":"2025-01-23T03:43:40.881978Z","shell.execute_reply.started":"2025-01-23T03:43:40.877799Z","shell.execute_reply":"2025-01-23T03:43:40.881167Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"test_data = TensorDataset(test_inputs, test_masks, test_labels)\ntest_sampler = RandomSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:43:46.555966Z","iopub.execute_input":"2025-01-23T03:43:46.556287Z","iopub.status.idle":"2025-01-23T03:43:46.560631Z","shell.execute_reply.started":"2025-01-23T03:43:46.556248Z","shell.execute_reply":"2025-01-23T03:43:46.559732Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"# 5. GPU가 정상 셋팅되었는지 확인(skip)","metadata":{}},{"cell_type":"markdown","source":"# 6. 모델 로드하기","metadata":{}},{"cell_type":"code","source":"num_labels = 3\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"skt/kogpt2-base-v2\", num_labels=num_labels)\nmodel.cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:44:22.179243Z","iopub.execute_input":"2025-01-23T03:44:22.179546Z","iopub.status.idle":"2025-01-23T03:44:25.777444Z","shell.execute_reply.started":"2025-01-23T03:44:22.179524Z","shell.execute_reply":"2025-01-23T03:44:25.776544Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d4af46c1da84ab982a31130f95ac616"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"GPT2ForSequenceClassification(\n  (transformer): GPT2Model(\n    (wte): Embedding(51200, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (score): Linear(in_features=768, out_features=3, bias=False)\n)"},"metadata":{}}],"execution_count":49},{"cell_type":"markdown","source":"# 7. 모델 학습","metadata":{}},{"cell_type":"code","source":"# 몇 번의 에포크(전체 데이터에 대한 학습 횟수)를 할 것인지 선택\nepochs = 3\n\n# 옵티마이저 선택\noptimizer = AdamW(model.parameters(), lr = 2e-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:45:28.153526Z","iopub.execute_input":"2025-01-23T03:45:28.153884Z","iopub.status.idle":"2025-01-23T03:45:28.162545Z","shell.execute_reply.started":"2025-01-23T03:45:28.153857Z","shell.execute_reply":"2025-01-23T03:45:28.161746Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"def metrics(predictions, labels):\n    # predictions: 모델이 예측한 결과값들의 리스트 또는 배열\n    # labels: 실제 정답 레이블들의 리스트 또는 배열\n\n    # 예측값과 실제 레이블을 별도의 변수에 할당\n    y_pred = predictions\n    y_true = labels\n\n    # 사용 가능한 메트릭들을 계산\n\n    # 정확도 (Accuracy)\n    # 전체 예측 중에서 올바르게 예측한 비율\n    accuracy = accuracy_score(y_true, y_pred)\n\n    # 매크로 평균 F1 점수 (Macro-averaged F1 Score)\n    # 클래스별로 F1 점수를 계산한 후, 그 평균을 구함\n    # zero_division=0 옵션은 분모가 0일 경우 0을 반환하도록 설정\n    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n\n    # 마이크로 평균 F1 점수 (Micro-averaged F1 Score)\n    # 전체 데이터에 대해 단일 F1 점수를 계산\n    # 클래스 불균형이 심한 경우에 적합\n    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n\n    # 가중 평균 F1 점수 (Weighted-averaged F1 Score)\n    # 각 클래스의 F1 점수에 해당 클래스의 샘플 수를 가중치로 곱한 후 평균을 구함\n    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n\n    # 계산된 메트릭 결과를 딕셔너리 형태로 리턴\n    metrics = {'accuracy': accuracy,\n               'f1_macro': f1_macro_average,\n               'f1_micro': f1_micro_average,\n               'f1_weighted': f1_weighted_average}\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:45:34.402490Z","iopub.execute_input":"2025-01-23T03:45:34.402815Z","iopub.status.idle":"2025-01-23T03:45:34.407886Z","shell.execute_reply.started":"2025-01-23T03:45:34.402789Z","shell.execute_reply":"2025-01-23T03:45:34.406950Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"def train_epoch(model, train_dataloader, optimizer, device):\n    \"\"\"\n    하나의 에포크 동안 모델을 학습시키는 함수입니다.\n\n    Parameters:\n    model (torch.nn.Module): 학습시킬 모델 객체.\n    train_dataloader (torch.utils.data.DataLoader): 학습 데이터셋의 DataLoader.\n    optimizer (torch.optim.Optimizer): 최적화 알고리즘을 구현하는 객체.\n    device (torch.device): 학습에 사용할 장치(CPU 또는 CUDA).\n\n    Returns:\n    float: 평균 학습 손실값.\n    \"\"\"\n\n    total_train_loss = 0  # 학습 손실을 누적할 변수 초기화\n    model.train()  # 모델을 학습 모드로 설정\n\n    # 학습 데이터로더를 순회하며 배치 단위로 학습\n    for step, batch in tqdm(enumerate(train_dataloader), desc=\"Training Batch\"):\n        batch = tuple(t.to(device) for t in batch)  # DataLoader에서 배치를 받아 각 텐서를 지정된 장치로 이동\n        b_input_ids, b_input_mask, b_labels = batch  # 배치에서 입력 ID, 마스크, 라벨 추출\n\n        # 모델에 배치를 전달하여 손실값 계산\n        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n\n        # 손실값 추출\n        loss = outputs.loss\n\n        optimizer.zero_grad()  # 기울기(gradient) 초기화\n        loss.backward()  # 역전파를 통해 기울기(gradient) 계산\n        optimizer.step()  # 매개변수 업데이트\n\n        total_train_loss += loss.item()  # 총 손실에 더함\n\n    avg_train_loss = total_train_loss / len(train_dataloader)  # 평균 학습 손실 계산\n\n    return avg_train_loss  # 평균 학습 손실 반환","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:45:45.330110Z","iopub.execute_input":"2025-01-23T03:45:45.330416Z","iopub.status.idle":"2025-01-23T03:45:45.336236Z","shell.execute_reply.started":"2025-01-23T03:45:45.330396Z","shell.execute_reply":"2025-01-23T03:45:45.335309Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def evaluate(model, validation_dataloader, device):\n    \"\"\"\n    모델을 사용하여 검증 데이터셋에 대한 평가를 수행하는 함수입니다.\n\n    Parameters:\n    model (torch.nn.Module): 평가할 모델 객체.\n    validation_dataloader (torch.utils.data.DataLoader): 검증 데이터셋의 DataLoader.\n    device (torch.device): 평가에 사용할 장치(CPU 또는 CUDA).\n\n    Returns:\n    float: 평균 검증 손실값.\n    dict: 다양한 평가 지표(metrics)에 대한 값들을 담은 사전.\n    \"\"\"\n\n    model.eval()  # 모델을 평가 모드로 설정\n\n    total_eval_loss = 0  # 검증 손실을 누적할 변수 초기화\n    predictions, true_labels = [], []  # 예측값과 실제 라벨값을 저장할 리스트 초기화\n\n    # 검증 데이터로더를 순회하며 배치 단위로 평가\n    for batch in validation_dataloader:\n        batch = tuple(t.to(device) for t in batch)  # 배치 데이터를 디바이스로 이동\n        b_input_ids, b_input_mask, b_labels = batch  # 배치에서 입력 ID, 마스크, 라벨 추출\n\n        with torch.no_grad():  # 기울기(gradient) 계산을 수행하지 않음\n            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n\n        # 모델 출력에서 손실값 추출\n        if outputs.loss is not None:\n            loss = outputs.loss\n            total_eval_loss += loss.item()  # 총 손실에 더함\n\n        logits = outputs.logits.detach().cpu().numpy()  # 모델 예측값(로짓)을 numpy 배열로 변환\n        label_ids = b_labels.to('cpu').numpy()  # 실제 라벨값을 numpy 배열로 변환\n\n        # 3개의 값 중 가장 큰 값을 예측한 인덱스로 결정 (예시: logits = [3.513, -0.309, -2.111] ==> 예측: 0)\n        predictions.extend(np.argmax(logits, axis=1).flatten()) # 예측된 클래스를 리스트에 추가\n        true_labels.extend(label_ids.flatten()) # 실제 레이블 값을 리스트에 추가\n\n    eval_metrics = metrics(predictions, true_labels)\n\n    return total_eval_loss / len(validation_dataloader), eval_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:45:57.747246Z","iopub.execute_input":"2025-01-23T03:45:57.747536Z","iopub.status.idle":"2025-01-23T03:45:57.753599Z","shell.execute_reply.started":"2025-01-23T03:45:57.747515Z","shell.execute_reply":"2025-01-23T03:45:57.752839Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"device = \"cuda\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:46:46.280369Z","iopub.execute_input":"2025-01-23T03:46:46.280671Z","iopub.status.idle":"2025-01-23T03:46:46.284516Z","shell.execute_reply.started":"2025-01-23T03:46:46.280649Z","shell.execute_reply":"2025-01-23T03:46:46.283532Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# 최소 검증 손실 초기화\nmin_val_loss = float('inf')\n\n# 메인 학습 & 평가 루프\nfor epoch_i in range(0, epochs):\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n\n    # 학습 단계\n    train_epoch(model, train_dataloader, optimizer, device)\n\n    print(\"\\nRunning Validation...\")\n    # 검증 단계\n    avg_val_loss, eval_metrics = evaluate(model, validation_dataloader, device)\n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\n    print(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\n    print(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\n    print(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))\n\n    # 검증 손실이 현재까지의 최소값보다 작은 경우 체크포인트 저장\n    if avg_val_loss < min_val_loss:\n        print(f\"Validation loss decreased ({min_val_loss:.2f} --> {avg_val_loss:.2f}).  Saving model ...\")\n        # 베스트 모델 저장\n        torch.save(model.state_dict(), 'model_checkpoint.pt')\n        # 최소 검증 손실 업데이트\n        min_val_loss = avg_val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T03:46:48.753383Z","iopub.execute_input":"2025-01-23T03:46:48.753661Z","iopub.status.idle":"2025-01-23T03:50:30.748371Z","shell.execute_reply.started":"2025-01-23T03:46:48.753641Z","shell.execute_reply":"2025-01-23T03:50:30.747576Z"}},"outputs":[{"name":"stdout","text":"======== Epoch 1 / 3 ========\n","output_type":"stream"},{"name":"stderr","text":"Training Batch: 97it [01:06,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nRunning Validation...\n  Validation Loss: 0.44\n  Accuracy: 0.83\n  F1 Macro: 0.78\n  F1 Micro: 0.83\n  F1 Weighted: 0.83\nValidation loss decreased (inf --> 0.44).  Saving model ...\n======== Epoch 2 / 3 ========\n","output_type":"stream"},{"name":"stderr","text":"Training Batch: 97it [01:09,  1.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nRunning Validation...\n  Validation Loss: 0.47\n  Accuracy: 0.81\n  F1 Macro: 0.78\n  F1 Micro: 0.81\n  F1 Weighted: 0.81\n======== Epoch 3 / 3 ========\n","output_type":"stream"},{"name":"stderr","text":"Training Batch: 97it [01:08,  1.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nRunning Validation...\n  Validation Loss: 0.49\n  Accuracy: 0.83\n  F1 Macro: 0.79\n  F1 Micro: 0.83\n  F1 Weighted: 0.83\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:59:42.460213Z","iopub.execute_input":"2025-01-23T04:59:42.460566Z","iopub.status.idle":"2025-01-23T04:59:42.465934Z","shell.execute_reply.started":"2025-01-23T04:59:42.460532Z","shell.execute_reply":"2025-01-23T04:59:42.465078Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# 8. 모델 로드 및 평가","metadata":{}},{"cell_type":"code","source":"# 베스트 모델 로드\nmodel.load_state_dict(torch.load(\"model_checkpoint.pt\"))\n\navg_val_loss, eval_metrics = evaluate(model, test_dataloader, device)\nprint(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\nprint(\"  Accuracy: {0:.2f}\".format(eval_metrics['accuracy']))\nprint(\"  F1 Macro: {0:.2f}\".format(eval_metrics['f1_macro']))\nprint(\"  F1 Micro: {0:.2f}\".format(eval_metrics['f1_micro']))\nprint(\"  F1 Weighted: {0:.2f}\".format(eval_metrics['f1_weighted']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T05:00:03.621302Z","iopub.execute_input":"2025-01-23T05:00:03.621632Z","iopub.status.idle":"2025-01-23T05:00:03.713360Z","shell.execute_reply.started":"2025-01-23T05:00:03.621608Z","shell.execute_reply":"2025-01-23T05:00:03.712210Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c4493010d792>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 베스트 모델 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_checkpoint.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mavg_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Test Loss: {0:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_val_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"markdown","source":"# 9. 추론하기(Inference)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}