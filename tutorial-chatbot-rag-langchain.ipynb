{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q langchain langchain-community langchain_huggingface chromadb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:09:24.511682Z","iopub.execute_input":"2025-01-23T06:09:24.512008Z","iopub.status.idle":"2025-01-23T06:10:05.819907Z","shell.execute_reply.started":"2025-01-23T06:09:24.511970Z","shell.execute_reply":"2025-01-23T06:10:05.818491Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 31.0.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 1. Use langchain RAG","metadata":{}},{"cell_type":"code","source":"import os\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:10:08.279850Z","iopub.execute_input":"2025-01-23T06:10:08.280258Z","iopub.status.idle":"2025-01-23T06:10:09.899635Z","shell.execute_reply.started":"2025-01-23T06:10:08.280214Z","shell.execute_reply":"2025-01-23T06:10:09.898612Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"your_API\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:21:10.771148Z","iopub.execute_input":"2025-01-23T06:21:10.771957Z","iopub.status.idle":"2025-01-23T06:21:10.777731Z","shell.execute_reply.started":"2025-01-23T06:21:10.771919Z","shell.execute_reply":"2025-01-23T06:21:10.776553Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T03:32:24.841782Z","iopub.execute_input":"2024-11-06T03:32:24.842623Z","iopub.status.idle":"2024-11-06T03:32:24.855683Z","shell.execute_reply.started":"2024-11-06T03:32:24.84255Z","shell.execute_reply":"2024-11-06T03:32:24.85326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.llms import HuggingFaceHub\n\n# set Korean embedding and llm odel\nhf_embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n\nhf_llm = HuggingFaceHub(\n    repo_id=\"skt/kogpt2-base-v2\",\n    model_kwargs={\"task\": \"text-generation\"} ## question-answering tasK X. text-generation\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:21:13.941499Z","iopub.execute_input":"2025-01-23T06:21:13.941883Z","iopub.status.idle":"2025-01-23T06:21:17.258577Z","shell.execute_reply.started":"2025-01-23T06:21:13.941846Z","shell.execute_reply":"2025-01-23T06:21:17.257413Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import requests\nfrom langchain.schema import Document\nfrom bs4 import BeautifulSoup\n\n# for Wikipedia documents (EN, KO)\n\n# from langchain_community.document_loaders import WikipediaLoader\n\n# By default, English documents (https://en.wikipedia.org))\n# def load_Wiki_docs(query):\n#     loader = WikipediaLoader(query=query, load_max_docs=1) # need !pip install wikipedia\n#     documents = loader.load()\n    \n#     text_splitter = RecursiveCharacterTextSplitter(\n#         chunk_size=1000,\n#         chunk_overlap=200\n#     )\n#     splits = text_splitter.split_documents(documents)\n    \n#     return splits\n\n\n# For Korean query, get results from Korean wikipedia website and crawl and parse results\ndef load_Korean_wiki_docs(topic):\n    url = f\"https://ko.wikipedia.org/wiki/{topic}\"\n    \n    response = requests.get(url)\n    response.raise_for_status()  # raise Exception when error occurs\n\n    # HTML parsing and extract body contents\n    soup = BeautifulSoup(response.text, 'html.parser')\n    content = soup.find('div', {'class': 'mw-parser-output'})  # find div including body contents \n    \n    # Extract contents\n    paragraphs = content.find_all('p')\n    text = \"\\n\".join([p.get_text() for p in paragraphs])  # concat all context in <p> tags \n \n    # convert to Document object (required for LangChain)\n    documents = [Document(page_content=text, metadata={\"source\": url})]\n    \n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200\n    )\n    splits = text_splitter.split_documents(documents)\n    \n    return splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:34:38.186803Z","iopub.execute_input":"2025-01-23T06:34:38.187653Z","iopub.status.idle":"2025-01-23T06:34:38.195620Z","shell.execute_reply.started":"2025-01-23T06:34:38.187610Z","shell.execute_reply":"2025-01-23T06:34:38.194364Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def create_vectorstore(splits): \n    vectorstore = Chroma.from_documents(documents=splits, embedding=hf_embeddings)\n    return vectorstore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:26:26.124577Z","iopub.execute_input":"2025-01-23T06:26:26.124990Z","iopub.status.idle":"2025-01-23T06:26:26.131204Z","shell.execute_reply.started":"2025-01-23T06:26:26.124949Z","shell.execute_reply":"2025-01-23T06:26:26.129831Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"topic = \"흑백요리사\"\n# Load wikipedia documents for this topic\nsplits = load_Korean_wiki_docs(topic) \n# Create vectorstore with this fetched docs\nvectorstore = create_vectorstore(splits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:38:04.288272Z","iopub.execute_input":"2025-01-23T06:38:04.288679Z","iopub.status.idle":"2025-01-23T06:38:05.073760Z","shell.execute_reply.started":"2025-01-23T06:38:04.288642Z","shell.execute_reply":"2025-01-23T06:38:05.072399Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"len(splits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:38:06.606978Z","iopub.execute_input":"2025-01-23T06:38:06.607413Z","iopub.status.idle":"2025-01-23T06:38:06.614321Z","shell.execute_reply.started":"2025-01-23T06:38:06.607375Z","shell.execute_reply":"2025-01-23T06:38:06.613041Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:38:09.614583Z","iopub.execute_input":"2025-01-23T06:38:09.614974Z","iopub.status.idle":"2025-01-23T06:38:09.621819Z","shell.execute_reply.started":"2025-01-23T06:38:09.614940Z","shell.execute_reply":"2025-01-23T06:38:09.620608Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]')]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"def create_rag_chain(vectorstore):\n    prompt_template = \"\"\"문맥을 참고하여 질문에 정확하고 간결하게 답하십시오.\n    문맥: {context}\n    질문: {question}\n    답변:\"\"\"\n    \n    PROMPT = PromptTemplate(\n        template=prompt_template, input_variables=[\"context\", \"question\"]\n    )\n\n    chain_type_kwargs = {\"prompt\": PROMPT}\n\n    # Make context shorter\n    # def short_context(context, max_length=300):\n    #     return context[:max_length] if len(context) > max_length else context\n    \n    # class ShortContextRetriever(BaseRetriever):\n    #     def __init__(self, retriever):\n    #         super().__init__()\n    #         self._retriever = retriever\n        \n    #     def get_relevant_documents(self, query):\n    #         docs = self._retriever.get_relevant_documents(query)\n    #         for doc in docs:\n    #             doc.page_content = short_context(doc.page_content)\n    #         return docs\n    \n    # retriever = ShortContextRetriever(vectorstore.as_retriever())\n\n    qa_chain = RetrievalQA.from_chain_type(\n        llm=hf_llm,\n        chain_type=\"stuff\",\n        retriever=vectorstore.as_retriever(),\n        chain_type_kwargs=chain_type_kwargs,\n        return_source_documents=True\n    )\n    \n    return qa_chain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:38:12.309451Z","iopub.execute_input":"2025-01-23T06:38:12.310472Z","iopub.status.idle":"2025-01-23T06:38:12.317044Z","shell.execute_reply.started":"2025-01-23T06:38:12.310427Z","shell.execute_reply":"2025-01-23T06:38:12.315814Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# create langchang RAG chain\nqa_chain = create_rag_chain(vectorstore)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:38:14.877048Z","iopub.execute_input":"2025-01-23T06:38:14.878264Z","iopub.status.idle":"2025-01-23T06:38:14.883335Z","shell.execute_reply.started":"2025-01-23T06:38:14.878212Z","shell.execute_reply":"2025-01-23T06:38:14.881972Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"question = \"심사위원?\"\n\n# result = qa_chain({\"query\": question})\nresult = qa_chain.invoke({\"query\": question})\n\nprint (\"결과:\")\nprint(result[\"result\"])\n\nprint(\"출처:\")\nfor doc in result[\"source_documents\"]:\n    print(doc.page_content)\n    print(\"---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:38:28.560857Z","iopub.execute_input":"2025-01-23T06:38:28.561348Z","iopub.status.idle":"2025-01-23T06:38:34.541237Z","shell.execute_reply.started":"2025-01-23T06:38:28.561304Z","shell.execute_reply":"2025-01-23T06:38:34.539927Z"}},"outputs":[{"name":"stdout","text":"결과:\n문맥을 참고하여 질문에 정확하고 간결하게 답하십시오.\n    문맥: 15년 11월 2일, 아모레퍼시픽이 업계와 면접 당사자에 따르면, 한 면접관은 영업관리직무 2차 면접 시험장에서 \"얼마 전 박근혜 대통령님이 국회에서 시정연설을 하며 강한 의지를 표하신 국정교과서에 대하여서 어떤 생각이냐\"라는 질문을 하였다. 응시자가 \"국정교과서가 사실상 바람직한 결정이라고 할 수 없다\" 며 의견을 피력하자, 면접관이 \"그래서 국정교과서 찬성, 반대예요?\" 응시자가 \"저는 다소 부정적이었지만, 박 대통령이 시정연설 말씀하셨듯이 어떠한 왜곡이나 미화도 없을 것이라며 객관성, 공정성을 기하겠다고 하였기 때문에 지켜볼 수 밖에 없다\" 면서 면접이 끝났다. 이후 응시자는 자신 SNS에 면접 상황을 전하면서 \"결국 탈락 소식을 접하였다. 영업관리 직무를 수행하는데 국정 교과서에 대한 견해가 무슨 의미가 있는 것인지 아모레퍼시픽으로부터 탈락 사유에 대한 공식적인 답변을 듣고 싶다\"고 밝혔다. 아모레퍼시픽은 \"사회에 대한 관심과 답변 내공, 결론 도출 논리성 등을 평가하기 위하여였을뿐, 다른 이유는 없었고, 지원자 성향은 합격 여부에 절대 영향을 주지 않았다. 당사의 채용은 공정성과 투명성을 확보하기 위하여서 개인 정치 성향, 종교, 학연 적절하지 않은 차별을 초래하는 사항들은 묻거나 평가에 반영하지 못하도록 규제하고 있다\"고 공식 입장을 밝혔다. 아모레퍼시픽은 공식 사과와 함께 재발방지를 약속하였지만, 대중들은 \"기업에서도 사상 검증을 하며 채용을 하는 것이냐\"며 비판을 하고 있다.\n[10]\n\n《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]\n\n이사회는 사내이사 3인, 사외이사 6인으로 구성된다. 2023년 기준으로, 사내이사는 서경배(대표이사 회장), 김승환(대표이사 사장), 박종만 이사이고, 사외이사는 이휘성, 조성진, 김종대, 안희준, 최인아, 이재연 이사이다.\n\n코로나 블루 사태로 극심한 실적 부진에 시달리는 아모레퍼시픽이 끝내 희망퇴직(의원퇴직)을 단행하였다. 50대 초반 김성환 대표가 발탁된 지 하루만이다. 위기의식을 불어넣겠다는 의지를 드러낸 아모레퍼시픽은 연이어 희망퇴직을 단행하며 조직을 줄이겠다는 의도를 감추지 않았다. 20년 11월 13일 업계에 따르면, 아모레퍼시픽은 이날 희망퇴직 관련 공지를 게재하고 희망자 모집을 시작하였다. 대상자는 15년차 이상 직원이다. 15년 이상 직원에게는 퇴직 위로금으로 근속연수에 5개월치를 더한 급여를, 20년차 이상 직원에게는 40개월치 급여 수준의 퇴직 위로금을 지급하는 것으로 알려졌다. 이 사태는 예고된 수순이었으며, 실적 부진 가장 큰 요인인 중국 내 이니스프리 정리하고 구조조정 작업을 진행하였다. 사업과 실적이 장기간 침체된 일부 브랜드에 힘을 빼고 있는 만큼 인력 감축은 불가피한 상황이다.\n[8]\n\n21년 4월 7일 페이스북 \"플라스틱 없이도 잘 산다\" 그룹을 통하여서 \"이니스프리 플라스틱 화장품 용기를 종이로 포장하여 소비자를 기만하였다. 이니스프리 세럼, 안쪽이 궁금하여 갈라보니 떡하니 플라스틱 병이 나온다. 소비자고발센터에 접수하였다.\"고 주장하였다. 댓글을 통하여서 소비자들은 \"불매운동 동참\"을 선언하였다. 이와 관련하여 아모레퍼시픽 측은 \"해당 제품은 무색 폴리에틸렌 재질 내 용기를 사용하고 겉면에 종의라벨을 씌운 플라스틱 저감 제품이며, 기존 제품 대비 51.8% 플라스틱을 절감하였다. 플라스택 용기 바깥을 싸고 있는 종이 라벨 역할을 보다 쉽게 설명하고자 페이퍼 보틀이라고 표기하게 됐지만, 제품 이름으로 용기 전체가 종이 재질로 인식될 수 있다는 부분을 간과하였다\"며 사과 입장을 밝혔다. 실제로 이 제품 설명자로에서는 \"제품 사용 후 종이 보틀과 가벼워진 플라스틱 용기는 각각 분리배출이 가능하다\" 고 설명되어 있다. \"소비자 기만\" 에서는 \"비슷한 용기를 먼저 만들어 사용한 외국 제품 명칭을 그대로 옮겨온 것\"이라는 것이 아모레퍼시픽 설명이다. 일각에서는 아모레퍼시픽이 \"그린워시\"를 하는 것이 아니냐는 의문도 제기됐다. 녹색분칠이라고도 하는데 기업이 실제로는 환경에 유해한 활동을 하지만 친환경적인 이미지로 광고하는 것을 말한다. 이에 대하여서 여성환경연대는 \"재활용도 안 되는 용기를 생산하는 업계에게 책임을 물고, 포장재 생산 단계에서 재활용이 쉽게 설계하고 용기 회수를 통하여 고품질 재활용으로 이어지도록 하여야 한다\"고 강조하였다.\n[9]\n    질문: 심사위원?\n    답변: 롯데백화점 본점 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품관 식품\n출처:\n15년 11월 2일, 아모레퍼시픽이 업계와 면접 당사자에 따르면, 한 면접관은 영업관리직무 2차 면접 시험장에서 \"얼마 전 박근혜 대통령님이 국회에서 시정연설을 하며 강한 의지를 표하신 국정교과서에 대하여서 어떤 생각이냐\"라는 질문을 하였다. 응시자가 \"국정교과서가 사실상 바람직한 결정이라고 할 수 없다\" 며 의견을 피력하자, 면접관이 \"그래서 국정교과서 찬성, 반대예요?\" 응시자가 \"저는 다소 부정적이었지만, 박 대통령이 시정연설 말씀하셨듯이 어떠한 왜곡이나 미화도 없을 것이라며 객관성, 공정성을 기하겠다고 하였기 때문에 지켜볼 수 밖에 없다\" 면서 면접이 끝났다. 이후 응시자는 자신 SNS에 면접 상황을 전하면서 \"결국 탈락 소식을 접하였다. 영업관리 직무를 수행하는데 국정 교과서에 대한 견해가 무슨 의미가 있는 것인지 아모레퍼시픽으로부터 탈락 사유에 대한 공식적인 답변을 듣고 싶다\"고 밝혔다. 아모레퍼시픽은 \"사회에 대한 관심과 답변 내공, 결론 도출 논리성 등을 평가하기 위하여였을뿐, 다른 이유는 없었고, 지원자 성향은 합격 여부에 절대 영향을 주지 않았다. 당사의 채용은 공정성과 투명성을 확보하기 위하여서 개인 정치 성향, 종교, 학연 적절하지 않은 차별을 초래하는 사항들은 묻거나 평가에 반영하지 못하도록 규제하고 있다\"고 공식 입장을 밝혔다. 아모레퍼시픽은 공식 사과와 함께 재발방지를 약속하였지만, 대중들은 \"기업에서도 사상 검증을 하며 채용을 하는 것이냐\"며 비판을 하고 있다.\n[10]\n---\n《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]\n---\n이사회는 사내이사 3인, 사외이사 6인으로 구성된다. 2023년 기준으로, 사내이사는 서경배(대표이사 회장), 김승환(대표이사 사장), 박종만 이사이고, 사외이사는 이휘성, 조성진, 김종대, 안희준, 최인아, 이재연 이사이다.\n\n코로나 블루 사태로 극심한 실적 부진에 시달리는 아모레퍼시픽이 끝내 희망퇴직(의원퇴직)을 단행하였다. 50대 초반 김성환 대표가 발탁된 지 하루만이다. 위기의식을 불어넣겠다는 의지를 드러낸 아모레퍼시픽은 연이어 희망퇴직을 단행하며 조직을 줄이겠다는 의도를 감추지 않았다. 20년 11월 13일 업계에 따르면, 아모레퍼시픽은 이날 희망퇴직 관련 공지를 게재하고 희망자 모집을 시작하였다. 대상자는 15년차 이상 직원이다. 15년 이상 직원에게는 퇴직 위로금으로 근속연수에 5개월치를 더한 급여를, 20년차 이상 직원에게는 40개월치 급여 수준의 퇴직 위로금을 지급하는 것으로 알려졌다. 이 사태는 예고된 수순이었으며, 실적 부진 가장 큰 요인인 중국 내 이니스프리 정리하고 구조조정 작업을 진행하였다. 사업과 실적이 장기간 침체된 일부 브랜드에 힘을 빼고 있는 만큼 인력 감축은 불가피한 상황이다.\n[8]\n---\n21년 4월 7일 페이스북 \"플라스틱 없이도 잘 산다\" 그룹을 통하여서 \"이니스프리 플라스틱 화장품 용기를 종이로 포장하여 소비자를 기만하였다. 이니스프리 세럼, 안쪽이 궁금하여 갈라보니 떡하니 플라스틱 병이 나온다. 소비자고발센터에 접수하였다.\"고 주장하였다. 댓글을 통하여서 소비자들은 \"불매운동 동참\"을 선언하였다. 이와 관련하여 아모레퍼시픽 측은 \"해당 제품은 무색 폴리에틸렌 재질 내 용기를 사용하고 겉면에 종의라벨을 씌운 플라스틱 저감 제품이며, 기존 제품 대비 51.8% 플라스틱을 절감하였다. 플라스택 용기 바깥을 싸고 있는 종이 라벨 역할을 보다 쉽게 설명하고자 페이퍼 보틀이라고 표기하게 됐지만, 제품 이름으로 용기 전체가 종이 재질로 인식될 수 있다는 부분을 간과하였다\"며 사과 입장을 밝혔다. 실제로 이 제품 설명자로에서는 \"제품 사용 후 종이 보틀과 가벼워진 플라스틱 용기는 각각 분리배출이 가능하다\" 고 설명되어 있다. \"소비자 기만\" 에서는 \"비슷한 용기를 먼저 만들어 사용한 외국 제품 명칭을 그대로 옮겨온 것\"이라는 것이 아모레퍼시픽 설명이다. 일각에서는 아모레퍼시픽이 \"그린워시\"를 하는 것이 아니냐는 의문도 제기됐다. 녹색분칠이라고도 하는데 기업이 실제로는 환경에 유해한 활동을 하지만 친환경적인 이미지로 광고하는 것을 말한다. 이에 대하여서 여성환경연대는 \"재활용도 안 되는 용기를 생산하는 업계에게 책임을 물고, 포장재 생산 단계에서 재활용이 쉽게 설계하고 용기 회수를 통하여 고품질 재활용으로 이어지도록 하여야 한다\"고 강조하였다.\n[9]\n---\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"docs = vectorstore.as_retriever().get_relevant_documents(question)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:38:44.062140Z","iopub.execute_input":"2025-01-23T06:38:44.062549Z","iopub.status.idle":"2025-01-23T06:38:44.124474Z","shell.execute_reply.started":"2025-01-23T06:38:44.062515Z","shell.execute_reply":"2025-01-23T06:38:44.123379Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2742417880.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  docs = vectorstore.as_retriever().get_relevant_documents(question)\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/아모레퍼시픽'}, page_content='15년 11월 2일, 아모레퍼시픽이 업계와 면접 당사자에 따르면, 한 면접관은 영업관리직무 2차 면접 시험장에서 \"얼마 전 박근혜 대통령님이 국회에서 시정연설을 하며 강한 의지를 표하신 국정교과서에 대하여서 어떤 생각이냐\"라는 질문을 하였다. 응시자가 \"국정교과서가 사실상 바람직한 결정이라고 할 수 없다\" 며 의견을 피력하자, 면접관이 \"그래서 국정교과서 찬성, 반대예요?\" 응시자가 \"저는 다소 부정적이었지만, 박 대통령이 시정연설 말씀하셨듯이 어떠한 왜곡이나 미화도 없을 것이라며 객관성, 공정성을 기하겠다고 하였기 때문에 지켜볼 수 밖에 없다\" 면서 면접이 끝났다. 이후 응시자는 자신 SNS에 면접 상황을 전하면서 \"결국 탈락 소식을 접하였다. 영업관리 직무를 수행하는데 국정 교과서에 대한 견해가 무슨 의미가 있는 것인지 아모레퍼시픽으로부터 탈락 사유에 대한 공식적인 답변을 듣고 싶다\"고 밝혔다. 아모레퍼시픽은 \"사회에 대한 관심과 답변 내공, 결론 도출 논리성 등을 평가하기 위하여였을뿐, 다른 이유는 없었고, 지원자 성향은 합격 여부에 절대 영향을 주지 않았다. 당사의 채용은 공정성과 투명성을 확보하기 위하여서 개인 정치 성향, 종교, 학연 적절하지 않은 차별을 초래하는 사항들은 묻거나 평가에 반영하지 못하도록 규제하고 있다\"고 공식 입장을 밝혔다. 아모레퍼시픽은 공식 사과와 함께 재발방지를 약속하였지만, 대중들은 \"기업에서도 사상 검증을 하며 채용을 하는 것이냐\"며 비판을 하고 있다.\\n[10]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/아모레퍼시픽'}, page_content='이사회는 사내이사 3인, 사외이사 6인으로 구성된다. 2023년 기준으로, 사내이사는 서경배(대표이사 회장), 김승환(대표이사 사장), 박종만 이사이고, 사외이사는 이휘성, 조성진, 김종대, 안희준, 최인아, 이재연 이사이다.\\n\\n코로나 블루 사태로 극심한 실적 부진에 시달리는 아모레퍼시픽이 끝내 희망퇴직(의원퇴직)을 단행하였다. 50대 초반 김성환 대표가 발탁된 지 하루만이다. 위기의식을 불어넣겠다는 의지를 드러낸 아모레퍼시픽은 연이어 희망퇴직을 단행하며 조직을 줄이겠다는 의도를 감추지 않았다. 20년 11월 13일 업계에 따르면, 아모레퍼시픽은 이날 희망퇴직 관련 공지를 게재하고 희망자 모집을 시작하였다. 대상자는 15년차 이상 직원이다. 15년 이상 직원에게는 퇴직 위로금으로 근속연수에 5개월치를 더한 급여를, 20년차 이상 직원에게는 40개월치 급여 수준의 퇴직 위로금을 지급하는 것으로 알려졌다. 이 사태는 예고된 수순이었으며, 실적 부진 가장 큰 요인인 중국 내 이니스프리 정리하고 구조조정 작업을 진행하였다. 사업과 실적이 장기간 침체된 일부 브랜드에 힘을 빼고 있는 만큼 인력 감축은 불가피한 상황이다.\\n[8]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/아모레퍼시픽'}, page_content='21년 4월 7일 페이스북 \"플라스틱 없이도 잘 산다\" 그룹을 통하여서 \"이니스프리 플라스틱 화장품 용기를 종이로 포장하여 소비자를 기만하였다. 이니스프리 세럼, 안쪽이 궁금하여 갈라보니 떡하니 플라스틱 병이 나온다. 소비자고발센터에 접수하였다.\"고 주장하였다. 댓글을 통하여서 소비자들은 \"불매운동 동참\"을 선언하였다. 이와 관련하여 아모레퍼시픽 측은 \"해당 제품은 무색 폴리에틸렌 재질 내 용기를 사용하고 겉면에 종의라벨을 씌운 플라스틱 저감 제품이며, 기존 제품 대비 51.8% 플라스틱을 절감하였다. 플라스택 용기 바깥을 싸고 있는 종이 라벨 역할을 보다 쉽게 설명하고자 페이퍼 보틀이라고 표기하게 됐지만, 제품 이름으로 용기 전체가 종이 재질로 인식될 수 있다는 부분을 간과하였다\"며 사과 입장을 밝혔다. 실제로 이 제품 설명자로에서는 \"제품 사용 후 종이 보틀과 가벼워진 플라스틱 용기는 각각 분리배출이 가능하다\" 고 설명되어 있다. \"소비자 기만\" 에서는 \"비슷한 용기를 먼저 만들어 사용한 외국 제품 명칭을 그대로 옮겨온 것\"이라는 것이 아모레퍼시픽 설명이다. 일각에서는 아모레퍼시픽이 \"그린워시\"를 하는 것이 아니냐는 의문도 제기됐다. 녹색분칠이라고도 하는데 기업이 실제로는 환경에 유해한 활동을 하지만 친환경적인 이미지로 광고하는 것을 말한다. 이에 대하여서 여성환경연대는 \"재활용도 안 되는 용기를 생산하는 업계에게 책임을 물고, 포장재 생산 단계에서 재활용이 쉽게 설계하고 용기 회수를 통하여 고품질 재활용으로 이어지도록 하여야 한다\"고 강조하였다.\\n[9]')]"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"docs = vectorstore.similarity_search(question, k=4)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:38:53.837842Z","iopub.execute_input":"2025-01-23T06:38:53.838410Z","iopub.status.idle":"2025-01-23T06:38:53.954693Z","shell.execute_reply.started":"2025-01-23T06:38:53.838356Z","shell.execute_reply":"2025-01-23T06:38:53.953544Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/아모레퍼시픽'}, page_content='15년 11월 2일, 아모레퍼시픽이 업계와 면접 당사자에 따르면, 한 면접관은 영업관리직무 2차 면접 시험장에서 \"얼마 전 박근혜 대통령님이 국회에서 시정연설을 하며 강한 의지를 표하신 국정교과서에 대하여서 어떤 생각이냐\"라는 질문을 하였다. 응시자가 \"국정교과서가 사실상 바람직한 결정이라고 할 수 없다\" 며 의견을 피력하자, 면접관이 \"그래서 국정교과서 찬성, 반대예요?\" 응시자가 \"저는 다소 부정적이었지만, 박 대통령이 시정연설 말씀하셨듯이 어떠한 왜곡이나 미화도 없을 것이라며 객관성, 공정성을 기하겠다고 하였기 때문에 지켜볼 수 밖에 없다\" 면서 면접이 끝났다. 이후 응시자는 자신 SNS에 면접 상황을 전하면서 \"결국 탈락 소식을 접하였다. 영업관리 직무를 수행하는데 국정 교과서에 대한 견해가 무슨 의미가 있는 것인지 아모레퍼시픽으로부터 탈락 사유에 대한 공식적인 답변을 듣고 싶다\"고 밝혔다. 아모레퍼시픽은 \"사회에 대한 관심과 답변 내공, 결론 도출 논리성 등을 평가하기 위하여였을뿐, 다른 이유는 없었고, 지원자 성향은 합격 여부에 절대 영향을 주지 않았다. 당사의 채용은 공정성과 투명성을 확보하기 위하여서 개인 정치 성향, 종교, 학연 적절하지 않은 차별을 초래하는 사항들은 묻거나 평가에 반영하지 못하도록 규제하고 있다\"고 공식 입장을 밝혔다. 아모레퍼시픽은 공식 사과와 함께 재발방지를 약속하였지만, 대중들은 \"기업에서도 사상 검증을 하며 채용을 하는 것이냐\"며 비판을 하고 있다.\\n[10]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《무명요리사》였다.[1]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/아모레퍼시픽'}, page_content='이사회는 사내이사 3인, 사외이사 6인으로 구성된다. 2023년 기준으로, 사내이사는 서경배(대표이사 회장), 김승환(대표이사 사장), 박종만 이사이고, 사외이사는 이휘성, 조성진, 김종대, 안희준, 최인아, 이재연 이사이다.\\n\\n코로나 블루 사태로 극심한 실적 부진에 시달리는 아모레퍼시픽이 끝내 희망퇴직(의원퇴직)을 단행하였다. 50대 초반 김성환 대표가 발탁된 지 하루만이다. 위기의식을 불어넣겠다는 의지를 드러낸 아모레퍼시픽은 연이어 희망퇴직을 단행하며 조직을 줄이겠다는 의도를 감추지 않았다. 20년 11월 13일 업계에 따르면, 아모레퍼시픽은 이날 희망퇴직 관련 공지를 게재하고 희망자 모집을 시작하였다. 대상자는 15년차 이상 직원이다. 15년 이상 직원에게는 퇴직 위로금으로 근속연수에 5개월치를 더한 급여를, 20년차 이상 직원에게는 40개월치 급여 수준의 퇴직 위로금을 지급하는 것으로 알려졌다. 이 사태는 예고된 수순이었으며, 실적 부진 가장 큰 요인인 중국 내 이니스프리 정리하고 구조조정 작업을 진행하였다. 사업과 실적이 장기간 침체된 일부 브랜드에 힘을 빼고 있는 만큼 인력 감축은 불가피한 상황이다.\\n[8]'),\n Document(metadata={'source': 'https://ko.wikipedia.org/wiki/아모레퍼시픽'}, page_content='21년 4월 7일 페이스북 \"플라스틱 없이도 잘 산다\" 그룹을 통하여서 \"이니스프리 플라스틱 화장품 용기를 종이로 포장하여 소비자를 기만하였다. 이니스프리 세럼, 안쪽이 궁금하여 갈라보니 떡하니 플라스틱 병이 나온다. 소비자고발센터에 접수하였다.\"고 주장하였다. 댓글을 통하여서 소비자들은 \"불매운동 동참\"을 선언하였다. 이와 관련하여 아모레퍼시픽 측은 \"해당 제품은 무색 폴리에틸렌 재질 내 용기를 사용하고 겉면에 종의라벨을 씌운 플라스틱 저감 제품이며, 기존 제품 대비 51.8% 플라스틱을 절감하였다. 플라스택 용기 바깥을 싸고 있는 종이 라벨 역할을 보다 쉽게 설명하고자 페이퍼 보틀이라고 표기하게 됐지만, 제품 이름으로 용기 전체가 종이 재질로 인식될 수 있다는 부분을 간과하였다\"며 사과 입장을 밝혔다. 실제로 이 제품 설명자로에서는 \"제품 사용 후 종이 보틀과 가벼워진 플라스틱 용기는 각각 분리배출이 가능하다\" 고 설명되어 있다. \"소비자 기만\" 에서는 \"비슷한 용기를 먼저 만들어 사용한 외국 제품 명칭을 그대로 옮겨온 것\"이라는 것이 아모레퍼시픽 설명이다. 일각에서는 아모레퍼시픽이 \"그린워시\"를 하는 것이 아니냐는 의문도 제기됐다. 녹색분칠이라고도 하는데 기업이 실제로는 환경에 유해한 활동을 하지만 친환경적인 이미지로 광고하는 것을 말한다. 이에 대하여서 여성환경연대는 \"재활용도 안 되는 용기를 생산하는 업계에게 책임을 물고, 포장재 생산 단계에서 재활용이 쉽게 설계하고 용기 회수를 통하여 고품질 재활용으로 이어지도록 하여야 한다\"고 강조하였다.\\n[9]')]"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# It seems vectorDB loading from embedding model works fine, but seems llm model does not.\n# Some Korean llm model seems to work fine in text-generation task, but for Question-Ansering task, we might need another approach.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T03:33:15.580119Z","iopub.execute_input":"2024-11-06T03:33:15.580617Z","iopub.status.idle":"2024-11-06T03:33:15.586739Z","shell.execute_reply.started":"2024-11-06T03:33:15.580573Z","shell.execute_reply":"2024-11-06T03:33:15.585086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Use QA pipeline with vectorstor similarity search","metadata":{}},{"cell_type":"code","source":"# import torch\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n\n# Load model and tokenizer\nmodel_name = \"yjgwak/klue-bert-base-finetuned-squard-kor-v1\"\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Set Q_A pipeline\nqa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:55:21.234638Z","iopub.execute_input":"2025-01-23T06:55:21.235142Z","iopub.status.idle":"2025-01-23T06:55:43.919094Z","shell.execute_reply.started":"2025-01-23T06:55:21.235101Z","shell.execute_reply":"2025-01-23T06:55:43.917475Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/635 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13e9974f124b4d979e4df71e48307d3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ac79a428937442f971da55fba67f947"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"181c4243468a4ee89f7e361f5bf2cee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/246k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"659207b02171424d95c6e9b9ae6fa60d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8526f21e52544b1bbb27d75a37f9b8cc"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Example: define question and context \nquestion = \"오늘 날씨 어때?\"\ncontext = \"오늘의 날씨는 맑고 따뜻한 기온이 유지될 것으로 보입니다.\"\n\n# model chain\nresult = qa_pipeline(question=question, context=context)\n\n# Result\nprint(\"질문:\", question)\nprint(\"답변:\", result['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T03:33:31.423141Z","iopub.execute_input":"2024-11-06T03:33:31.423617Z","iopub.status.idle":"2024-11-06T03:33:31.555002Z","shell.execute_reply.started":"2024-11-06T03:33:31.423565Z","shell.execute_reply":"2024-11-06T03:33:31.553646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# search context in VectorStore\ndef retrieve_context(question, vectorstore):\n    docs = vectorstore.similarity_search(question, k=4)\n    if docs:\n        return \" \".join([doc.page_content for doc in docs])\n        # return docs[0].page_content  # return first relevant doc\n    else:\n        return None\n\n# Generate answer based on query and searched context similar to RAG chain\ndef answer_question_with_context(question, vectorstore):\n    context = retrieve_context(question, vectorstore)\n    if context:\n        result = qa_pipeline(question=question, context=context)\n        return result['answer'], context  # return answer and used source doc\n    else:\n        return \"관련 문맥을 찾지 못했습니다.\", None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T03:33:31.556691Z","iopub.execute_input":"2024-11-06T03:33:31.557138Z","iopub.status.idle":"2024-11-06T03:33:31.566617Z","shell.execute_reply.started":"2024-11-06T03:33:31.557096Z","shell.execute_reply":"2024-11-06T03:33:31.565007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example\nquestion = \"심사위원을 누가 맡았어?\"\n\nanswer, used_context = answer_question_with_context(question, vectorstore)\n\nprint(\"질문:\", question)\nprint(\"답변:\", answer)\nprint(\"사용된 문맥:\", used_context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T03:33:31.56847Z","iopub.execute_input":"2024-11-06T03:33:31.568961Z","iopub.status.idle":"2024-11-06T03:33:31.902837Z","shell.execute_reply.started":"2024-11-06T03:33:31.568917Z","shell.execute_reply":"2024-11-06T03:33:31.901412Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Use Gemini+RAG","metadata":{}},{"cell_type":"code","source":"# It seems the best and simple and cost-free option when OpenAI api cannot be used.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T03:33:31.904985Z","iopub.execute_input":"2024-11-06T03:33:31.905918Z","iopub.status.idle":"2024-11-06T03:33:31.912362Z","shell.execute_reply.started":"2024-11-06T03:33:31.905848Z","shell.execute_reply":"2024-11-06T03:33:31.910324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install -q langchain langchain-community langchain_huggingface chromadb google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:55:43.921162Z","iopub.execute_input":"2025-01-23T06:55:43.921554Z","iopub.status.idle":"2025-01-23T06:55:56.819920Z","shell.execute_reply.started":"2025-01-23T06:55:43.921517Z","shell.execute_reply":"2025-01-23T06:55:56.817975Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# pip install google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T03:33:52.362965Z","iopub.execute_input":"2024-11-06T03:33:52.363439Z","iopub.status.idle":"2024-11-06T03:33:52.369738Z","shell.execute_reply.started":"2024-11-06T03:33:52.363381Z","shell.execute_reply":"2024-11-06T03:33:52.368235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.schema import Document\nfrom langchain.llms import OpenAI\nimport google.generativeai as genai\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T06:57:33.082369Z","iopub.execute_input":"2025-01-23T06:57:33.083419Z","iopub.status.idle":"2025-01-23T06:57:33.584042Z","shell.execute_reply.started":"2025-01-23T06:57:33.083372Z","shell.execute_reply":"2025-01-23T06:57:33.582773Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR-API-KEY\"\ngenai_api_key = \"your_API\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:02:02.097443Z","iopub.execute_input":"2025-01-23T07:02:02.097871Z","iopub.status.idle":"2025-01-23T07:02:02.102871Z","shell.execute_reply.started":"2025-01-23T07:02:02.097831Z","shell.execute_reply":"2025-01-23T07:02:02.101669Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"genai.configure(api_key=genai_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:04:21.967541Z","iopub.execute_input":"2025-01-23T07:04:21.968348Z","iopub.status.idle":"2025-01-23T07:04:21.973513Z","shell.execute_reply.started":"2025-01-23T07:04:21.968295Z","shell.execute_reply":"2025-01-23T07:04:21.972328Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# 1. Gemini model\ngemini_model = genai.GenerativeModel('gemini-1.5-flash')\n\n# 2. embedding model\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:04:27.216716Z","iopub.execute_input":"2025-01-23T07:04:27.217157Z","iopub.status.idle":"2025-01-23T07:04:31.341058Z","shell.execute_reply.started":"2025-01-23T07:04:27.217116Z","shell.execute_reply":"2025-01-23T07:04:31.339892Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"prompt = f\"Question: 집에 가고 싶다 \\nAnswer : \"\n    # response = gemini_model(prompt)\n    \nresponse = gemini_model.generate_content(prompt)\nanswer = response.candidates[0].content.parts[0].text\n\nprint(answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:21:18.597279Z","iopub.execute_input":"2025-01-23T07:21:18.597721Z","iopub.status.idle":"2025-01-23T07:21:21.771954Z","shell.execute_reply.started":"2025-01-23T07:21:18.597682Z","shell.execute_reply":"2025-01-23T07:21:21.770816Z"}},"outputs":[{"name":"stdout","text":"Several answers are possible depending on the context and desired response. Here are a few options:\n\n* **\"알겠어요. 곧 집에 갈 수 있도록 도와드릴게요.\"** (Algesseoyo. Got jip-e gal su itdorok dowadeurilgesoyo.) - \"Okay. I'll help you get home soon.\"  This is a suitable response if you're in a position to help the person get home.\n\n* **\"조금만 더 힘내요! 집에 가면 편히 쉴 수 있어요.\"** (Jogeumman deo himnaeyo! Jip-e gamyeon pyeonhi swil su isseoyo.) - \"Hang in there a little longer! You can rest comfortably when you get home.\" This is encouraging and offers hope.\n\n* **\"집에 가는 길 조심히 가세요.\"** (Jip-e ganeun gil josimhi gaseyo.) - \"Be careful on your way home.\" This is a polite and caring response.\n\n* **\"무슨 일이에요?\"** (Museun irieyo?) - \"What's wrong?\" This is appropriate if you want to understand the reason behind their desire to go home.\n\n* **\"언제쯤 집에 갈 수 있어요?\"** (Eonjejjeum jip-e gal su isseoyo?) - \"When can you go home?\" This is a question to clarify their situation.\n\n\nThe best answer depends on the situation.  Consider what kind of response is most appropriate given the context.\n\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"from langchain.vectorstores import Chroma\n# sample docs\ndocs = [\n    Document(page_content=\"한국어 챗봇은 자연어 처리 기술을 사용하여 사용자와 대화를 나눕니다.\", metadata={\"source\": \"doc1\"}),\n    Document(page_content=\"인공지능을 활용한 챗봇은 여러 산업에서 사용되고 있습니다.\", metadata={\"source\": \"doc2\"}),\n    Document(page_content=\"한국어와 영어를 동시에 지원하는 챗봇이 점점 늘어나고 있습니다.\", metadata={\"source\": \"doc3\"}),\n    Document(page_content=\"챗봇은 고객 서비스를 개선하고 사용자 경험을 향상시키는 데 중요한 역할을 합니다.\", metadata={\"source\": \"doc4\"})\n]\n\n# to avoid collision with previous one\npersist_directory = \"./new_chroma_db\"\n\nvectorstore = Chroma.from_documents(docs, embedding=embedding_model, persist_directory=\"./chroma_db\")","metadata":{"execution":{"iopub.status.busy":"2025-01-23T07:37:23.772540Z","iopub.execute_input":"2025-01-23T07:37:23.772965Z","iopub.status.idle":"2025-01-23T07:37:23.880828Z","shell.execute_reply.started":"2025-01-23T07:37:23.772926Z","shell.execute_reply":"2025-01-23T07:37:23.879627Z"},"trusted":true},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# RAG using prompt\ndef rag_chatbot(question):\n    context_doc = vectorstore.similarity_search(question, k=4)\n    # context = context_doc[0].page_content if context_doc else \"정보를 찾을 수 없습니다.\"\n\n    context = \" \".join([doc.page_content for doc in context_doc])\n    \n    prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n    # response = gemini_model(prompt)\n    \n    response = gemini_model.generate_content(prompt)\n    answer = response.candidates[0].content.parts[0].text\n\n    return answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:40:31.402962Z","iopub.execute_input":"2025-01-23T07:40:31.403397Z","iopub.status.idle":"2025-01-23T07:40:31.409510Z","shell.execute_reply.started":"2025-01-23T07:40:31.403357Z","shell.execute_reply":"2025-01-23T07:40:31.408470Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# sample question\nquestion = \"너는 누구야?\"\nresponse = rag_chatbot(question)\n\nprint(\"질문:\", question)\nprint(\"답변:\", response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T07:40:33.125592Z","iopub.execute_input":"2025-01-23T07:40:33.126019Z","iopub.status.idle":"2025-01-23T07:40:34.280660Z","shell.execute_reply.started":"2025-01-23T07:40:33.125970Z","shell.execute_reply":"2025-01-23T07:40:34.279383Z"}},"outputs":[{"name":"stdout","text":"질문: 너는 누구야?\n답변: 저는 한국어로 응답하는 인공지능 챗봇입니다.  제가 제공하는 정보는 제가 학습한 데이터를 바탕으로 생성됩니다.  위에 제시된 넷플릭스 프로그램 《흑백요리사: 요리 계급 전쟁》에 대한 정보를 포함하여 다양한 주제에 대해 질문에 답변할 수 있습니다.\n\n","output_type":"stream"}],"execution_count":52}]}